

# Computer Architecture

A computer is a machine to **process** information (data):

* A **processor** (typically an integrated circuit) performs **operations** on data
* It processes **input** information to generate a desired **output** information
* Input/output data loaded/stored from/to **memory** a data storage area
* Electronic devices operate **binary** signals (electricity on/off)
* Binary expressed by two symbols - `0` and `1` ➜ **binary digits** (bits)
* Numbers, text represented as **binary patterns** ➜ combinations of zeros and ones

Example binary patterns (8bit ASCII encoding):

Binary     | Character
-----------|------------
0011 0000  | 0 (zero)
0011 0010  | 1 (one)
0011 0010  | 2 (two)
0100 0001  | A
0100 0010  | B
0100 0100  | C

## Machine Code

Machine code (machine language) ➜ **instructions** executed by a processor 

* Instruction ➜ **operation code** (opcode), **operand**
* Operand ➜ (memory address to the) data to operate on 
* Opcodes & operands encoded as **binary code**
* Machine code **programm** ➜ sequence of instructions (opcodes & operands) 
* **Assembly language**
  - Symbolic representation of machine instructions
  - Symbolic names for opcodes ➜ **mnemonic codes**
* **Assembler** ➜ translates assembly language into machine code

Example machine operations code (Intel 8085):

Opcode (binary) | Mnemonic | Description
----------------|----------|---------------------------------
1000 0111       | ADD      | Add contents of register to accumulator
0011 1010       | LDA      | Load data from memory address
0011 0010       | STA      | Store data to memory address
0111 1001       | MOV      | Move data from between registers
1100 0011       | JMP      | Jump to memory address

### Object Code

Object code is a sequence of instructions in machine code generated by an assembler

* Executable programs are typically build from reusable **code fragments** (sub-program, function/modules)
  - Fragments get individually compiled (translated) into object code
  - A complete program it then build by combining various object code fragments
  - Individual fragments are referenced using a **symbol** (function name)
* **Object file** (relocatable format machine code)
  - File format use to store object code and related data (e.g. ELF)
  - Structured as separated **segments**/sections of different types of data
* A **linker** program combines object code to generate executable machine code
  - **Relocation** assigns load addresses to various object code fragments
  - A linker resolves symbols using assigned memory locations and patching the calling object code to that location (call instruction reference)
* A **loader** places executable machine code into (main) memory and prepares it for execution
  - Allocates regions in memory corresponding to segments in the machine code
  - A program loader is part of a computer operating system (starts the program once its loader)
  - A microcontroller typically do not have a loader, instead the executable machine code is starter directly from memory

### Object Files

Object files contain five kinds of information

* Header: Metadata, code size, format specification, etc.
* Object code: Binary instructions and data generated by an assembler(/compiler)
* Relocation: List of places in the object code a linker needs to change the address of
* Symbols: Global symbols defined in the module, symbols to be imported from other modules
* Debugging: Information about the object code need by the linker for debugging

ELF (Executable and Linking Format) file com in three flavors:

* Relocatable: Create by assemblers(/compilers), need to processed by a linker
* Executable: Address relocation done, symbols resolved (except for shared library symbols), ready for execution
* Shared object: Shared libraries including symbol information for linkers and executable code for run-time


## Processor

A **processing unit**, aka CPU (Central Processing Unit):

* Active part of a computer ➜ **datapath** and **control**
  - Control ➜ Commands the datapath, memory, and input/output devices according to machine instructions 
  - Datapath ➜ Components of a processor that perform arithmetic operations
* Processors ➜ **fetch** (read) instruction from memory before instruction **execute**

## Processor Architectures

Separation of processor and memory distinguishes programmable computers

### Control-flow Architecture

**Stored program computer**: instructions and data stored in memory

* **Harvard architecture**: Separate memory for data and instructions
  - Two sets of address/data buses between processor and memory
  - Allow simultaneous memory fetches
* **Modified Harvard architecture**: Separate memory for data and instructions
  - Instruction memory can be used to store data
  - Two pieces of data can be loaded in parallel
* **Von Neumann architecture**: Single memory holds data and instructions
  - Single set of address/data buses between processor and memory
  - Values in memory interpreted depending on a control signal
* Current instruction identified by the **instruction pointer** (program counter)
* Sequential instruction processing (fetch, execute, and complete) one at a time
* The instruction pointer is advanced sequentially except for control transfer
* Instructions executed in **control flow order**

### Data-flow Architecture

* Instructions executed based on the availability of input arguments, **data flow order**
* Conceptually **no instruction pointer** required since execute based on data dependencies
* Inherently more parallel with the potential to execute many instructions at the same time 

Control- vs data-flow trade-offs:

* Ease of programming
* Ease of compilation
* Extraction of parallelism (performance)
* Hardware complexity

## Instruction Set Architecture

The Instruction Set Architecture (ISA) specifies how a programmer sees instructions to be executed:

* Defines an **interface between software and hardware** enabling the implementation of programs
* Modern ISAs are mostly control-flow architectures: x86, ARM, MIPS, SPARC, POWER
* ISAs have a very long lifetime (compared to µarch) staying backwards-compatible while being extended with additional instructions

The ISA includes all functionality exposed to the programmer:

* Instructions: Opcodes, addressing modes, data types, registers, condition code...
* Memory: Address space, alignment, virtual memory...
* Interrupt/exception handling, access control, priority/privileges
* Task/thread management, power & thermal management
* Multi-threading & multi-processing support

**ISA Types**:

* Reduced Instruction Set Computer (RISC)
  - Compact, uniform instruction size ➜ easier to decode ➜ facilitates pipelines
  - Complexity implemented as series of smaller instructions
  - More lines of code ➜ bigger memory footprint
  - Allow effective compiler optimization
* Complex Instruction Set Computer (CISC)
  - Extremely specific instructions (doing as much work as possible)
  - Instructions not uniform in size ➜ difficult to decode
  - Pipelines requires break down of instructions into smaller components at processor level
  - High code density
  - Complex processor hardware
* Very long instruction word (VLIW)
  - Execute multiple instructions concurrently, in parallel
  - Instruction Level Parallelism (ILP)
  - Compiler bundles multiple instructions that can be executed in parallel into a single long instruction
  - 

## Microarchitecture

The Microarchitecture (µarch) is the implementation of the ISA under specific design constrains and goals:

* The microprocessor is the physical representation (circuits) of the ISA and µarch
* Example: add instruction (ISA) vs adder implementation (µarch) [bit serial, ripple carry, carry lockahead, etc.]
* Example: x86 ISA has many implementations - Intel [2,3,4]86, Intel Pentium [Pro, 4], Intel Core, AMD...
* Design points: cost, performance, power consumption, reliability, time to market...

The µarch defines anything done in hardware and can execute instructions in any order (e.g. data-flow order) as long it obeys the **semantics specified by the ISA**:

* Pipeline instruction execution (Intel 486)
* Multiple instructions at a time (Intel Pentium)
* Out-of-order execution (Intel Pentium Pro)
* Speculative execution, branch prediction, prefetching
* Memory access scheduling policy, cache (levels, size, associativity, replacement policy)
* Clock gating, dynamic voltage and frequency scaling (energy efficiency)
* Error handling, correction
* Superscalar processing, multiple instructions (VLIW architecture, Intel Itanium)
* SIMD processing (vector/array processors, GPUs)
* Systolic arrays (Google tensor-processor)
